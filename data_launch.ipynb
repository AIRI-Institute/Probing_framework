{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Union\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    from typing import Literal  # type: ignore\n",
    "except:\n",
    "    from typing_extensions import Literal  # type: ignore\n",
    "\n",
    "from transformers.utils import logging\n",
    "\n",
    "logger = logging.get_logger(\"probing\")\n",
    "\n",
    "\n",
    "class BasicPlot:\n",
    "    PARAMS_FIELD = \"params\"\n",
    "    RESULTS_FIELD = \"results\"\n",
    "\n",
    "    LANGUAGE_FIELD = \"task_language\"\n",
    "    TASK_FIELD = \"task_category\"\n",
    "    MODEL_NAME_FIELD = \"hf_model_name\"\n",
    "    CLASSIFIER_FIELD = \"classifier_name\"\n",
    "    METRIC_FIELD = \"metric_names\"\n",
    "    FAMILY_FIELD = \"family\"\n",
    "    FULL_LANGUAGE_FIELD = \"full_language\"\n",
    "\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_field: str = \"layer\",\n",
    "        y_field: str = \"task_category\",\n",
    "        value_field: str = \"metric_scores\",\n",
    "    ):\n",
    "        self.x_field = x_field\n",
    "        self.y_field = y_field\n",
    "        self.value_field = value_field\n",
    "\n",
    "    @staticmethod\n",
    "    def get_logs(paths: List[Path], filename: str = \"log.json\") -> List[Path]:\n",
    "        logs_path = []\n",
    "        for path in paths:\n",
    "            internal_log_paths = path.glob(f\"**/*/{filename}\")\n",
    "            for log_path in internal_log_paths:\n",
    "                if log_path not in logs_path:\n",
    "                    logs_path.append(log_path)\n",
    "        return logs_path\n",
    "\n",
    "    @lru_cache()\n",
    "    def aggregation(\n",
    "        self,\n",
    "        res_paths: Union[Path, List[Path]],\n",
    "        metric_name: Literal[\"f1\", \"accuracy\"] = \"f1\",\n",
    "        stage: Literal[\"val\", \"test\"] = \"test\",\n",
    "    ) -> pd.DataFrame:\n",
    "        aggregated_data_dict: Dict[Any, Any] = {\n",
    "            BasicPlot.LANGUAGE_FIELD: [],\n",
    "            BasicPlot.TASK_FIELD: [],\n",
    "            BasicPlot.MODEL_NAME_FIELD: [],\n",
    "            BasicPlot.CLASSIFIER_FIELD: [],\n",
    "            BasicPlot.METRIC_FIELD: [],\n",
    "            BasicPlot.FAMILY_FIELD: [],\n",
    "            BasicPlot.FULL_LANGUAGE_FIELD: [],\n",
    "            \"layer\": [],\n",
    "            \"metric_scores\": [],\n",
    "            \"log_path\": [],\n",
    "        }\n",
    "        lang_file = pd.read_csv('all_languages.csv', delimiter=';')\n",
    "        if not isinstance(res_paths, list):\n",
    "            res_paths = [res_paths]\n",
    "        res_paths = [Path(path).resolve() for path in res_paths]\n",
    "\n",
    "        log_paths = BasicPlot.get_logs(res_paths)\n",
    "        if len(log_paths) == 0:\n",
    "            logger.warning(\"None logs were found for the given paths.\")\n",
    "        \n",
    "        remm = []\n",
    "        for log_path in log_paths:\n",
    "            with open(log_path) as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            params = data[BasicPlot.PARAMS_FIELD]\n",
    "            all_results = data[BasicPlot.RESULTS_FIELD]\n",
    "\n",
    "            lang = params[BasicPlot.LANGUAGE_FIELD]\n",
    "            task_category = params[BasicPlot.TASK_FIELD]\n",
    "            model_name = params[BasicPlot.MODEL_NAME_FIELD]\n",
    "            classifier_name = params[BasicPlot.CLASSIFIER_FIELD]\n",
    "            stage_scores = all_results[f\"{stage}_score\"][metric_name]\n",
    "            lang_full = lang_file.loc[lang_file['Codes'] == lang]['Language'].values[0]\n",
    "            family = lang_file.loc[lang_file['Codes'] == lang]['Family'].values[0]\n",
    "            \n",
    "            if {'task_language': lang, 'task_category': task_category, 'hf_model_name': model_name, 'classifier_name': classifier_name, 'metric_name': metric_name} not in remm:\n",
    "                remm.append({'task_language': lang, 'task_category': task_category, 'hf_model_name': model_name, 'classifier_name': classifier_name, 'metric_name': metric_name})\n",
    "                for layer_num, stage_res in stage_scores.items():\n",
    "                    layer = int(layer_num) + 1\n",
    "\n",
    "                    if isinstance(stage_res, list):\n",
    "                        aggregated_scores = np.mean(stage_res)\n",
    "                    else:\n",
    "                        raise NotImplementedError()\n",
    "\n",
    "                    aggregated_data_dict[BasicPlot.LANGUAGE_FIELD].append(lang)\n",
    "                    aggregated_data_dict[BasicPlot.TASK_FIELD].append(task_category)\n",
    "                    aggregated_data_dict[BasicPlot.MODEL_NAME_FIELD].append(model_name)\n",
    "                    aggregated_data_dict[BasicPlot.CLASSIFIER_FIELD].append(classifier_name)\n",
    "                    aggregated_data_dict[BasicPlot.METRIC_FIELD].append(metric_name)\n",
    "                    aggregated_data_dict[BasicPlot.FAMILY_FIELD].append(family)\n",
    "                    aggregated_data_dict[BasicPlot.FULL_LANGUAGE_FIELD].append(lang_full)\n",
    "\n",
    "\n",
    "                    aggregated_data_dict[\"layer\"].append(layer)\n",
    "                    aggregated_data_dict[\"metric_scores\"].append(aggregated_scores)\n",
    "                    aggregated_data_dict[\"log_path\"].append(str(log_path))\n",
    "\n",
    "        return pd.DataFrame(aggregated_data_dict)\n",
    "    \n",
    "pivot_table = BasicPlot().aggregation(res_paths = Path(\"Probing_framework/\"))\n",
    "df_data = pivot_table.reset_index()\n",
    "df_data.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "lang_file = pd.read_csv('all_languages.csv', delimiter=';')\n",
    "hits = glob(\"Probing_framework/results/*/*/*.json\", recursive=True)\n",
    "datasets = {}\n",
    "for file_name in hits: \n",
    "    file = open(file_name)\n",
    "    data_file = json.loads(file.read())\n",
    "    lang = data_file['params']['task_language']\n",
    "    model_name = data_file['params']['hf_model_name']\n",
    "    if model_name not in datasets.keys():\n",
    "        datasets[model_name] = {}\n",
    "    a = lang_file.loc[lang_file['Codes'].isin([lang])]\n",
    "    lang_full = a.iloc[0]['Language']\n",
    "    cat = data_file['params']['task_category']\n",
    "    if lang_full not in datasets[model_name].keys():\n",
    "        datasets[model_name][lang_full] = {}\n",
    "    datasets[model_name][lang_full][cat] = {}\n",
    "    datasets[model_name][lang_full][cat]['training'] = data_file['params']['original_classes_ratio']['tr']\n",
    "    datasets[model_name][lang_full][cat]['validation'] = data_file['params']['original_classes_ratio']['va']\n",
    "    datasets[model_name][lang_full][cat]['test'] = data_file['params']['original_classes_ratio']['te']\n",
    "with open('datasets.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(datasets, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
